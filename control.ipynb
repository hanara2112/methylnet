{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e156338e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/autrio/miniconda3/envs/NRC/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import load_npz, identity, issparse\n",
    "from numpy.linalg import pinv, matrix_rank, svd\n",
    "from scipy.linalg import solve_discrete_are, eigvals, norm\n",
    "from scipy.sparse.linalg import eigs as sparse_eigs\n",
    "\n",
    "import networkx as nx\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "A_path = \"o2/A_final_stable.npz\"      # repo file\n",
    "genes_path = \"o2/genes_final.csv\"     # expects column 'gene' or single column\n",
    "expr_path = \"data/expr_common_full.csv\"  # expression table: rows = samples, cols = genes (or transpose)\n",
    "\n",
    "T_gram = 40               # finite horizon for Gramian approximations (trace)\n",
    "m_cont = 30               # depth for controllability rank checks\n",
    "max_greedy_size = 200     # safety cap on greedy selected set size\n",
    "objective = \"rank\"  # options: 'gramian_trace', 'min_eig', 'rank'\n",
    "seed_with_structural = True\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb22c197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded A: (8378, 8378) sparse: True\n",
      "Loaded genes list, n = 8378\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(A_path):\n",
    "    raise FileNotFoundError(f\"{A_path} not found. Run from repo root or change path.\")\n",
    "\n",
    "A = load_npz(A_path).astype(float)\n",
    "n = A.shape[0]\n",
    "print(\"Loaded A:\", A.shape, \"sparse:\", issparse(A))\n",
    "\n",
    "GENES = None\n",
    "if os.path.exists(genes_path):\n",
    "    gdf = pd.read_csv(genes_path, header=0)\n",
    "    # try to infer gene column\n",
    "    if \"gene\" in gdf.columns:\n",
    "        GENES = gdf[\"gene\"].astype(str).tolist()\n",
    "    else:\n",
    "        # if single column\n",
    "        GENES = gdf.iloc[:,0].astype(str).tolist()\n",
    "    assert len(GENES) == n, f\"Gene list length {len(GENES)} != A.shape[0] {n}\"\n",
    "    print(\"Loaded genes list, n =\", len(GENES))\n",
    "else:\n",
    "    # fallback: generate numeric gene names\n",
    "    GENES = [f\"g{i}\" for i in range(n)]\n",
    "    print(\"genes file not found; using synthetic gene names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52247ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression data              MB-0006  MB-0028  MB-0035  MB-0046  MB-0050  MB-0053  MB-0054  \\\n",
      "Hugo_Symbol                                                                  \n",
      "A2M           2.4671  -0.8292  -0.3122  -0.1450  -0.7651   1.1408   2.1077   \n",
      "A4GALT       -0.4412   0.4318  -1.9995   0.5552   0.1737  -1.5991  -0.8954   \n",
      "AAAS          0.7683  -0.7058   0.0129  -0.6430  -1.2141  -0.4286  -0.1641   \n",
      "AACS         -1.3245   0.2130  -0.0626   0.6073  -0.8968  -1.5375  -1.0142   \n",
      "AADACL2       0.6082  -0.5639  -0.2895   1.1172  -0.3718   1.0195   0.3245   \n",
      "...              ...      ...      ...      ...      ...      ...      ...   \n",
      "ZWINT        -0.6574   0.3098   0.0264   1.4851  -1.6942   1.0965   1.0998   \n",
      "ZXDC         -1.5690  -0.2822  -0.5964  -0.2320   0.4545  -1.9882  -2.7958   \n",
      "ZYG11B        0.0940  -0.1729   0.4592  -1.0761   0.3331   0.3317   0.9267   \n",
      "ZYX          -0.7766  -2.5108   0.5377  -0.2600   0.1423  -3.6021  -2.0316   \n",
      "ZZEF1        -0.9416  -1.4202  -1.0823   0.2592  -0.4428  -3.4440  -3.7185   \n",
      "\n",
      "             MB-0062  MB-0064  MB-0068  ...  MB-7279  MB-7281  MB-7283  \\\n",
      "Hugo_Symbol                             ...                              \n",
      "A2M          -0.4490   1.4625   2.3368  ...  -1.7789  -0.2546  -1.9168   \n",
      "A4GALT       -0.6437  -1.6113  -1.3177  ...   0.7735  -0.0863  -1.6124   \n",
      "AAAS         -0.3192   2.4339   1.0824  ...   1.3102  -0.5108   0.6422   \n",
      "AACS         -2.1341  -0.4573  -0.6578  ...   0.4481   0.1038  -1.4500   \n",
      "AADACL2       1.5023  -0.3120  -0.0785  ...  -0.0557   0.9368   0.8668   \n",
      "...              ...      ...      ...  ...      ...      ...      ...   \n",
      "ZWINT         1.2479  -0.0895   0.2103  ...   1.1641   1.3103   1.1239   \n",
      "ZXDC         -1.6498  -1.3399  -2.4097  ...   2.1836   0.5744   1.3056   \n",
      "ZYG11B        0.0748   1.1286   0.5334  ...   0.5046   2.1028   0.0389   \n",
      "ZYX          -2.3072  -2.4681  -1.6517  ...  -0.9198   0.8009   1.1836   \n",
      "ZZEF1        -4.4660  -2.2871  -3.2632  ...  -0.3086  -0.5665  -1.1335   \n",
      "\n",
      "             MB-7285  MB-7288  MB-7289  MB-7291  MB-7292  MB-7293  MB-7296  \n",
      "Hugo_Symbol                                                                 \n",
      "A2M          -0.0388   0.7219   1.2983   0.3608   0.3968   1.1543  -0.0627  \n",
      "A4GALT        1.6162  -1.0039   0.1427  -1.0167  -0.1205   0.2985   0.0214  \n",
      "AAAS         -0.9703  -0.3325  -0.9442  -0.2705  -0.8041  -0.1257  -0.2497  \n",
      "AACS         -1.2485  -0.8126  -1.0992  -1.2694  -0.9498  -1.9809   0.3786  \n",
      "AADACL2       0.0892  -0.3274  -0.6126  -0.5805   0.5108  -0.4685   0.6391  \n",
      "...              ...      ...      ...      ...      ...      ...      ...  \n",
      "ZWINT        -0.1140   0.5581  -0.9643   1.0819   1.3959  -1.3504   1.0613  \n",
      "ZXDC         -1.1442  -1.5177  -1.0490  -1.4243  -1.8298  -1.1924  -0.6583  \n",
      "ZYG11B       -0.5821  -1.5858  -1.0386  -1.6004  -1.8699  -1.0172  -2.1186  \n",
      "ZYX           0.1964  -0.2669   0.8444   0.0372   0.3934   0.1393  -0.9353  \n",
      "ZZEF1        -1.1754  -2.3565  -0.6333  -0.9361  -1.1966  -2.1520  -0.3002  \n",
      "\n",
      "[11171 rows x 1417 columns]\n",
      "Loaded expression: (11171, 1417)\n",
      "Using global median across samples as x*\n",
      "x* :  [-0.0865 -0.0885 -0.0417 ... -0.0282 -0.0304 -0.1358]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(expr_path):\n",
    "    expr_df = pd.read_csv(expr_path, index_col=0)\n",
    "    print(\"Expression data\", expr_df)\n",
    "    print(\"Loaded expression:\", expr_df.shape)\n",
    "    # Ensure columns correspond to gene list (attempt to align)\n",
    "    # If expr has same columns as genes, reorder; else assume same order\n",
    "    if set(expr_df.columns) >= set(GENES):\n",
    "        expr_df = expr_df[GENES]   # reorder to genes list\n",
    "    else:\n",
    "        # if mismatch, try transpose if rows are genes\n",
    "        if set(expr_df.index) >= set(GENES):\n",
    "            expr_df = expr_df.T\n",
    "            if set(expr_df.columns) >= set(GENES):\n",
    "                expr_df = expr_df[GENES]\n",
    "        else:\n",
    "            print(\"Warning: gene names in expression file do not match gene list. Assuming same ordering.\")\n",
    "            # then we assume expr_df.columns order == genes\n",
    "    # Build x*: median of 'normal' samples if it can find them, else global median\n",
    "    # Look for typical normal identifiers in sample names\n",
    "    sample_names = expr_df.index.astype(str).tolist()\n",
    "    normal_mask = [(\"normal\" in s.lower() or \"adj\" in s.lower() or \"tumor-adj\" in s.lower()) for s in sample_names]\n",
    "    if any(normal_mask):\n",
    "        x_star = expr_df.loc[np.array(normal_mask)].median(axis=0).values\n",
    "        print(\"Using median of detected normal samples as x*\")\n",
    "    else:\n",
    "        x_star = expr_df.median(axis=0).values\n",
    "        print(\"Using global median across samples as x*\")\n",
    "else:\n",
    "    # fallback: zero vector\n",
    "    x_star = np.zeros(n)\n",
    "    print(\"Expression file not found; using x* = zero vector (NOT recommended).\")\n",
    "\n",
    "assert x_star.shape[0] == n, \"x* length mismatch\"\n",
    "print(\"x* : \", x_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ff37bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        gene     degree\n",
      "0     IGFBP7  66.265798\n",
      "1     TUBA1C  54.582640\n",
      "2     UBE2G2  52.866151\n",
      "3      ITGB1  48.068044\n",
      "4      SPCS1  44.949030\n",
      "5     RPS27A  44.542268\n",
      "6     HNRNPK  40.958177\n",
      "7      GSG1L  39.184623\n",
      "8  GABARAPL2  38.430002\n",
      "9       MXD3  37.708785\n"
     ]
    }
   ],
   "source": [
    "if issparse(A):\n",
    "    absA = abs(A)\n",
    "    degrees = np.array(absA.sum(axis=0)).ravel() + np.array(absA.sum(axis=1)).ravel() # in+out\n",
    "else:\n",
    "    absA = np.abs(A)\n",
    "    degrees = absA.sum(axis=0) + absA.sum(axis=1)\n",
    "\n",
    "# rank genes by degree\n",
    "rank_idx = np.argsort(-degrees)\n",
    "top_k = 20\n",
    "top_genes = [(GENES[i], float(degrees[i])) for i in rank_idx[:top_k]]\n",
    "top_df = pd.DataFrame(top_genes, columns=[\"gene\",\"degree\"])\n",
    "print(top_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17499b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ctrl(top_k: int = 5, genes_list: list = None) -> list:\n",
    "    if genes_list is None:\n",
    "        genes_list = []\n",
    "        k_control = top_k\n",
    "        selected_control_idx = rank_idx[:k_control].tolist()\n",
    "        control_gene_names = [GENES[i] for i in selected_control_idx]\n",
    "        print(\"Selected control genes (k={}):\".format(k_control), control_gene_names)\n",
    "    else:\n",
    "        selected_control_idx = []\n",
    "        for g in genes_list:\n",
    "            if g in GENES:\n",
    "                idx = GENES.index(g)\n",
    "                selected_control_idx.append(idx)\n",
    "            else:\n",
    "                print(f\"Warning: gene {g} not found in gene list; skipping.\")\n",
    "        k_control = len(selected_control_idx)\n",
    "        control_gene_names = [GENES[i] for i in selected_control_idx]\n",
    "        print(\"Selected control genes (k={}):\".format(k_control), control_gene_names)\n",
    "\n",
    "    B = np.zeros((n, k_control))\n",
    "    for j, idx in enumerate(selected_control_idx):\n",
    "        B[idx, j] = 1.0   # direct actuation\n",
    "        \n",
    "    return B, selected_control_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76f3b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected control genes (k=3): ['TP53', 'BRCA1', 'EGFR']\n",
      "Selected control genes (k=5): ['IGFBP7', 'TUBA1C', 'UBE2G2', 'ITGB1', 'SPCS1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], shape=(8378, 5)),\n",
       " [3238, 7535, 7603, 3372, 6662])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_ctrl(genes_list=[\"TP53\", \"BRCA1\", \"EGFR\"])\n",
    "select_ctrl()  # default top "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd1474a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structural_driver_nodes(A_sparse, genes):\n",
    "    \"\"\"\n",
    "    Construct a bipartite graph (left copy L, right copy R).\n",
    "    For every directed edge u->v in A, add (u_L, v_R).\n",
    "    Compute maximum matching; unmatched right nodes are driver nodes (Liu et al).\n",
    "    \"\"\"\n",
    "    if not issparse(A_sparse):\n",
    "        A_sparse = A_sparse\n",
    "    n = A_sparse.shape[0]\n",
    "    # Build directed edges from sparse matrix\n",
    "    Acoo = A_sparse.tocoo()\n",
    "    G = nx.DiGraph()\n",
    "    # bipartite graph as networkx Graph:\n",
    "    B = nx.DiGraph()\n",
    "    # Add nodes\n",
    "    L_nodes = [f\"l_{i}\" for i in range(n)]\n",
    "    R_nodes = [f\"r_{i}\" for i in range(n)]\n",
    "    BG = nx.Graph()\n",
    "    BG.add_nodes_from(L_nodes, bipartite=0)\n",
    "    BG.add_nodes_from(R_nodes, bipartite=1)\n",
    "    # Add edges (u_L, v_R) for each nonzero A[u,v]\n",
    "    for u, v in zip(Acoo.row, Acoo.col):\n",
    "        BG.add_edge(f\"l_{u}\", f\"r_{v}\")\n",
    "    # maximum bipartite matching (networkx returns dict)\n",
    "    matching = nx.algorithms.bipartite.matching.hopcroft_karp_matching(BG, top_nodes=L_nodes)\n",
    "    # matching maps both ways; extract matched right nodes\n",
    "    matched_right = set()\n",
    "    for k,v in matching.items():\n",
    "        if k.startswith(\"l_\"):\n",
    "            matched_right.add(v)\n",
    "    # unmatched right nodes are driver nodes (their r_i absent from matched_right)\n",
    "    unmatched_r = [i for i in range(n) if f\"r_{i}\" not in matched_right]\n",
    "    driver_genes = [GENES[i] for i in unmatched_r]\n",
    "    return unmatched_r, driver_genes, matching\n",
    "\n",
    "\n",
    "def A_pwr_precomp(A_sparse, T):\n",
    "    \"\"\"Return a list of functions that compute A^t @ v efficiently.\n",
    "       For moderate n we produce dense powers. For large n keep sparse logic: compute iteratively.\n",
    "    \"\"\"\n",
    "    n = A_sparse.shape[0]\n",
    "    if issparse(A_sparse) and n > 2000:\n",
    "        # for large sparse, we'll just return None and compute power via iterative multiplication when needed\n",
    "        return None\n",
    "    else:\n",
    "        A_dense = A_sparse.toarray() if issparse(A_sparse) else A_sparse\n",
    "        powers = [np.eye(n)]\n",
    "        cur = np.eye(n)\n",
    "        for _ in range(1, T):\n",
    "            cur = A_dense.dot(cur)\n",
    "            powers.append(cur.copy())\n",
    "        return powers\n",
    "\n",
    "def B_gramian_Tr(A_sparse, B_mat, T, A_powers=None):\n",
    "    # W_T = sum_{i=0}^{T-1} A^i B B^T (A^i)^T\n",
    "    # trace(W_T) = sum_{i=0}^{T-1} trace(B^T (A^i)^T A^i B) = sum ||A^i B||_F^2\n",
    "    n, k = B_mat.shape\n",
    "    total = 0.0\n",
    "    if A_powers is not None:\n",
    "        # use powers to compute A^i B quickly: A_powers[i] @ B\n",
    "        for i in range(T):\n",
    "            AiB = A_powers[i].dot(B_mat)\n",
    "            total += np.sum(AiB * AiB)   # Frobenius squared\n",
    "    else:\n",
    "        # iterative multiplication\n",
    "        cur = B_mat.copy()\n",
    "        for i in range(T):\n",
    "            total += np.sum(cur * cur)\n",
    "            cur = A_sparse.dot(cur)\n",
    "    return float(total)\n",
    "\n",
    "def B_min_eig(A_sparse, B_mat, T):\n",
    "    # Build W explicitly (only for smaller n)\n",
    "    n, k = B_mat.shape\n",
    "    if n > 1200:\n",
    "        return np.nan\n",
    "    if issparse(A_sparse):\n",
    "        A = A_sparse.toarray()\n",
    "    else:\n",
    "        A = A_sparse\n",
    "    W = np.zeros((n,n))\n",
    "    cur = B_mat.copy()\n",
    "    for i in range(T):\n",
    "        W += cur.dot(cur.T)\n",
    "        cur = A.dot(cur)\n",
    "    eigs = np.linalg.eigvalsh(W)\n",
    "    return float(np.min(eigs))\n",
    "\n",
    "def B_ctrlability_rank(A_sparse, B_mat, m):\n",
    "    # build [B, A B, A^2 B, ...] up to m terms and compute rank\n",
    "    n, k = B_mat.shape\n",
    "    if k == 0:\n",
    "        return 0  # no actuators => rank zero (avoid calling matrix_rank on empty arrays)\n",
    "    cols = [B_mat]\n",
    "    cur = B_mat.copy()\n",
    "    for i in range(1, min(m, n)):\n",
    "        cur = A_sparse.dot(cur)\n",
    "        cols.append(cur.copy())\n",
    "    M = np.hstack(cols)\n",
    "    r = matrix_rank(M)\n",
    "    return int(r)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc1c6cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isfinite\n",
    "\n",
    "def compute_Z_krylov(A_sparse, idx, T=T_gram, tol=1e-8, max_rank=None):\n",
    "    \"\"\"\n",
    "    Compute low-rank factor Z (n x r) approximating finite-horizon discrete Gramian\n",
    "      W_T = sum_{t=0}^{T-1} (A^t b) (A^t b)^T\n",
    "    for b = e_idx, using a Krylov basis approach.\n",
    "    Returns Z numpy array shape (n, r) where r <= T.\n",
    "    Remarks:\n",
    "      - Works for sparse or dense A (uses A.dot(v)).\n",
    "      - Builds orthonormal basis V = [v1..vr] and small S = sum_{i} (V^T w_i)(V^T w_i)^T.\n",
    "      - Final W_approx = V S V^T, and we return Z = V @ sqrtm(S) (via eig-decomp of S).\n",
    "    \"\"\"\n",
    "    n = A_sparse.shape[0]\n",
    "    # basis vector b\n",
    "    b = np.zeros(n)\n",
    "    b[idx] = 1.0\n",
    "    # helper to multiply A * vec\n",
    "    Aop = A_sparse.dot if issparse(A_sparse) else (lambda x: A_sparse.dot(x))\n",
    "\n",
    "    V_cols = []            # list of numpy arrays (orthonormal basis vectors)\n",
    "    S = None               # small Gramian in V coordinates (r x r), updated incrementally\n",
    "    # current vector w = A^i b (starting with i=0: w = b)\n",
    "    w = b.copy()\n",
    "    # iterate for T steps\n",
    "    for t in range(T):\n",
    "        # project w onto current V to get coords c = V^T w\n",
    "        if len(V_cols) == 0:\n",
    "            # first vector, create new basis vector from w\n",
    "            wnorm = np.linalg.norm(w)\n",
    "            if wnorm < tol:\n",
    "                # zero vector (rare) -> return empty Z or small placeholder\n",
    "                return np.zeros((n, 0))\n",
    "            v_new = w / wnorm\n",
    "            V_cols.append(v_new)\n",
    "            # S becomes [[ (v_new^T w)^2 ]] = [[wnorm^2]]\n",
    "            S = np.array([[wnorm * wnorm]], dtype=float)\n",
    "        else:\n",
    "            # form c = V^T w\n",
    "            Vmat = np.column_stack(V_cols)  # n x r\n",
    "            c = Vmat.T.dot(w)               # r-vector\n",
    "            # compute residual r = w - V c\n",
    "            residual = w - Vmat.dot(c)\n",
    "            res_norm = np.linalg.norm(residual)\n",
    "            if res_norm > tol:\n",
    "                # append new orthonormal basis vector\n",
    "                v_new = residual / res_norm\n",
    "                # update S to incorporate new coordinate dimension\n",
    "                r_old = S.shape[0]\n",
    "                # expand S to (r_old+1 x r_old+1)\n",
    "                S_new = np.zeros((r_old + 1, r_old + 1), dtype=float)\n",
    "                S_new[:r_old, :r_old] = S\n",
    "                # compute new c_full = [c; res_norm] is the coordinates of w in new basis\n",
    "                c_full = np.concatenate([c, np.array([res_norm])])\n",
    "                S_new += np.outer(c_full, c_full)\n",
    "                S = S_new\n",
    "                V_cols.append(v_new)\n",
    "            else:\n",
    "                # residual nearly zero: w lies in span(V). S += c c^T\n",
    "                S += np.outer(c, c)\n",
    "        # advance w <- A * w for next power\n",
    "        w = Aop(w)\n",
    "        # optional early stop if rank exceeds max_rank\n",
    "        if (max_rank is not None) and (S.shape[0] >= max_rank):\n",
    "            # still accumulate this step's contribution if needed: project current w and add then break\n",
    "            # We already handled current w above; break now to limit rank growth\n",
    "            break\n",
    "\n",
    "    # At end, build Z = V * sqrtm(S)\n",
    "    if S is None or len(V_cols) == 0:\n",
    "        return np.zeros((n, 0))\n",
    "    Vmat = np.column_stack(V_cols)   # n x r\n",
    "    # small eigen-decomposition of S (r x r)\n",
    "    evals, evecs = np.linalg.eigh(S)\n",
    "    # clip tiny negative numerical noise\n",
    "    evals[evals < 0] = 0.0\n",
    "    # discard tiny eigenvalues\n",
    "    keep = evals > (tol * np.max(evals) if np.max(evals) > 0 else tol)\n",
    "    if np.sum(keep) == 0:\n",
    "        # all tiny -> return empty\n",
    "        return np.zeros((n, 0))\n",
    "    evals_kept = evals[keep]\n",
    "    evecs_kept = evecs[:, keep]\n",
    "    # sqrt(S) = evecs_kept * diag(sqrt(evals_kept)) * evecs_kept^T\n",
    "    # but Z = V * (evecs_kept * diag(sqrt(evals_kept))) -> compute small R = evecs_kept * sqrt(evals_kept)\n",
    "    R_small = evecs_kept * np.sqrt(evals_kept)[np.newaxis, :]\n",
    "    Z = Vmat.dot(R_small)   # n x r_eff\n",
    "    return Z\n",
    "\n",
    "# Precompute Zs for candidate pool (Krylov-based)\n",
    "def precompute_basis_Zs_krylov(A_sparse, candidate_indices, T=T_gram, tol=1e-8, max_rank=None, parallel=False):\n",
    "    \"\"\"\n",
    "    Build Zdict: index -> Z (n x r_i) using compute_Z_krylov.\n",
    "    parallel: not implemented in this snippet (could use multiprocessing).\n",
    "    \"\"\"\n",
    "    Zdict = {}\n",
    "    t0 = time.time()\n",
    "    for idx in tqdm(candidate_indices, desc=\"Precomputing Z (Krylov)\"):\n",
    "        try:\n",
    "            Z = compute_Z_krylov(A_sparse, idx, T=T, tol=tol, max_rank=max_rank)\n",
    "            Zdict[idx] = Z\n",
    "        except Exception as e:\n",
    "            print(f\"[Z compute error] idx {idx}: {e}\")\n",
    "            Zdict[idx] = np.zeros((A_sparse.shape[0], 0))\n",
    "    dt = time.time() - t0\n",
    "    total_rank = sum(Z.shape[1] for Z in Zdict.values())\n",
    "    print(f\"Precomputed Z for {len(candidate_indices)} candidates in {dt:.1f}s; total rank sum {total_rank}\")\n",
    "    return Zdict\n",
    "\n",
    "# Fast objective computations using Zdict (unchanged from earlier)\n",
    "def gramian_trace_from_Zlist(Zlist):\n",
    "    if len(Zlist) == 0:\n",
    "        return 0.0\n",
    "    s = 0.0\n",
    "    for Z in Zlist:\n",
    "        s += float(np.sum(Z * Z))\n",
    "    return s\n",
    "\n",
    "def gramian_min_eig_from_Zlist(Zlist, tol=1e-12):\n",
    "    if len(Zlist) == 0:\n",
    "        return 0.0\n",
    "    Z_concat = np.hstack([Z for Z in Zlist if Z.shape[1] > 0])\n",
    "    if Z_concat.size == 0:\n",
    "        return 0.0\n",
    "    S = Z_concat.T.dot(Z_concat)   # small matrix r_total x r_total\n",
    "    # eigenvalues of W are eigenvalues of S\n",
    "    evals = np.linalg.eigvalsh(S)\n",
    "    # numerical floor\n",
    "    evals[evals < tol] = 0.0\n",
    "    return float(np.min(evals)) if evals.size > 0 else 0.0\n",
    "\n",
    "# Modified greedy selection that uses the Krylov Zdict (same interface as previous)\n",
    "def greedy_selection_with_Zs_krylov(A_sparse, genes, Zdict, candidate_pool, seed_indices=None,\n",
    "                                    objective=\"gramian_trace\", T=T_gram, m_cont=30, max_selected=200, verbose=True):\n",
    "    n = A_sparse.shape[0]\n",
    "    selected = []\n",
    "    if seed_indices:\n",
    "        selected = list(seed_indices)\n",
    "    available = set(candidate_pool) - set(selected)\n",
    "    Z_selected = [Zdict[i] for i in selected] if len(selected) > 0 else []\n",
    "    # initial objective\n",
    "    if objective == \"gramian_trace\":\n",
    "        cur_val = gramian_trace_from_Zlist(Z_selected)\n",
    "    elif objective == \"min_eig\":\n",
    "        cur_val = gramian_min_eig_from_Zlist(Z_selected)\n",
    "    elif objective == \"rank\":\n",
    "        B_current = np.zeros((n, len(selected)))\n",
    "        for j, idx in enumerate(selected):\n",
    "            B_current[idx, j] = 1.0\n",
    "        cur_val = B_ctrlability_rank(A_sparse, B_current, m_cont)\n",
    "    else:\n",
    "        cur_val = gramian_trace_from_Zlist(Z_selected)\n",
    "    if verbose:\n",
    "        print(\"Initial objective ({}) = {:.6g} (selected {} genes)\".format(objective, cur_val, len(selected)))\n",
    "    iter_count = 0\n",
    "    while iter_count < max_selected and len(selected) < n and len(available) > 0:\n",
    "        iter_count += 1\n",
    "        best_gain = -np.inf\n",
    "        best_gene = None\n",
    "        best_new_val = None\n",
    "        # iterate candidate pool only\n",
    "        for g in available:\n",
    "            Zcand_list = Z_selected + [Zdict[g]]\n",
    "            if objective == \"gramian_trace\":\n",
    "                val = gramian_trace_from_Zlist(Zcand_list)\n",
    "                gain = val - cur_val\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain; best_new_val = val; best_gene = g\n",
    "            elif objective == \"min_eig\":\n",
    "                val = gramian_min_eig_from_Zlist(Zcand_list)\n",
    "                gain = val - cur_val\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain; best_new_val = val; best_gene = g\n",
    "            elif objective == \"rank\":\n",
    "                # compute rank increase cheaply for one added actuator\n",
    "                Bcand = np.zeros((n, len(selected) + 1))\n",
    "                for j, idx in enumerate(selected):\n",
    "                    Bcand[idx, j] = 1.0\n",
    "                Bcand[g, -1] = 1.0\n",
    "                val = B_ctrlability_rank(A_sparse, Bcand, m_cont)\n",
    "                if val > cur_val and (best_gene is None or val > best_new_val):\n",
    "                    best_gain = val - cur_val; best_new_val = val; best_gene = g\n",
    "            else:\n",
    "                val = gramian_trace_from_Zlist(Zcand_list)\n",
    "                gain = val - cur_val\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain; best_new_val = val; best_gene = g\n",
    "        if best_gene is None:\n",
    "            if verbose:\n",
    "                print(\"No candidate in pool improved objective. Stopping.\")\n",
    "            break\n",
    "        selected.append(best_gene)\n",
    "        available.remove(best_gene)\n",
    "        Z_selected.append(Zdict[best_gene])\n",
    "        cur_val = best_new_val\n",
    "        if verbose:\n",
    "            print(f\"Iter {iter_count}: added {genes[best_gene]} (idx {best_gene}), new obj={cur_val:.6g}, selected={len(selected)}\")\n",
    "        # quick stop if rank full\n",
    "        if objective != \"rank\":\n",
    "            B_curr = np.zeros((n, len(selected)))\n",
    "            for j, idx in enumerate(selected):\n",
    "                B_curr[idx, j] = 1.0\n",
    "            r = B_ctrlability_rank(A_sparse, B_curr, m_cont)\n",
    "            if r == n:\n",
    "                if verbose:\n",
    "                    print(\"Controllability rank reached n. Stopping greedy.\")\n",
    "                break\n",
    "        else:\n",
    "            if cur_val == n:\n",
    "                if verbose:\n",
    "                    print(\"Rank objective reached n. Stopping greedy.\")\n",
    "                break\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb9809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structural unmatched indices already computed earlier\n",
    "unmatched_indices, driver_genes, matching = structural_driver_nodes(A, GENES)\n",
    "print(\"structural lower bound:\", len(unmatched_indices))\n",
    "\n",
    "# build candidate pool: union of structural unmatched nodes + top degree genes\n",
    "top_k_for_pool = 500   # adjust based on resources (e.g., 200 - 2000)\n",
    "top_candidates = list(rank_idx[:top_k_for_pool])\n",
    "candidate_pool = sorted(set(unmatched_indices).union(set(top_candidates)))\n",
    "print(\"Candidate pool size:\", len(candidate_pool))\n",
    "\n",
    "# precompute Z for candidate pool (this is the expensive-but-one-time step)\n",
    "Zdict = precompute_basis_Zs_krylov(A, candidate_pool, T=T_gram, tol=1e-8, max_rank=None)\n",
    "\n",
    "\n",
    "# run greedy selection using Zdict\n",
    "seed = unmatched_indices if seed_with_structural else None\n",
    "selected = greedy_selection_with_Zs_krylov(A, GENES, Zdict, candidate_pool, seed_indices=seed,\n",
    "                                           objective=objective, T=T_gram, m_cont=m_cont,\n",
    "                                           max_selected=max_greedy_size, verbose=True)\n",
    "\n",
    "# save results\n",
    "df_sel = pd.DataFrame({\"index\": selected, \"gene\": [GENES[i] for i in selected]})\n",
    "df_sel.to_csv(\"greedy_selected_drivers_Zbased.csv\", index=False)\n",
    "print(\"Saved greedy_selected_drivers_Zbased.csv\")\n",
    "\n",
    "# final rank check using B_final built from selected set\n",
    "B_final = np.zeros((n, len(selected)))\n",
    "for j, idx in enumerate(selected):\n",
    "    B_final[idx, j] = 1.0\n",
    "final_rank = B_ctrlability_rank(A, B_final, m_cont)\n",
    "print(\"Final controllability rank with selected set:\", final_rank, \"out of\", n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f72e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genes = [    \n",
    "    \"ZNF512\",\n",
    "    \"ZNF525\",\n",
    "    \"ZNF205\",\n",
    "    \"SH3GL1\",\n",
    "    \"ZNF550\",\n",
    "    \"SLC5A3\",\n",
    "    \"ZNF787\",\n",
    "    \"PIK3R4\",\n",
    "    \"POLN\",\n",
    "    \"EPG5\",\n",
    "    \"WDR53\",\n",
    "    \"ALDH16A1\",\n",
    "    \"NRBP1\",\n",
    "    \"ARFRP1\",\n",
    "    \"EEF1G\",\n",
    "    \"PTTG1IP\",\n",
    "    \"LTB4R\",\n",
    "    \"QTRT1\",\n",
    "    \"VPS18\",\n",
    "    \"PCSK4\",\n",
    "    \"TPM1\",\n",
    "    \"APP\",\n",
    "    \"NXNL1\",\n",
    "    \"PLEKHN1\",\n",
    "    \"ZNF587\",\n",
    "    \"NEURL4\",\n",
    "    \"SRPK3\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1b87e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected control genes (k=27): ['ZNF512', 'ZNF525', 'ZNF205', 'SH3GL1', 'ZNF550', 'SLC5A3', 'ZNF787', 'PIK3R4', 'POLN', 'EPG5', 'WDR53', 'ALDH16A1', 'NRBP1', 'ARFRP1', 'EEF1G', 'PTTG1IP', 'LTB4R', 'QTRT1', 'VPS18', 'PCSK4', 'TPM1', 'APP', 'NXNL1', 'PLEKHN1', 'ZNF587', 'NEURL4', 'SRPK3']\n"
     ]
    }
   ],
   "source": [
    "B, selected = select_ctrl(genes_list=selected_genes)\n",
    "# B, selected = select_ctrl(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac4eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NRC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
